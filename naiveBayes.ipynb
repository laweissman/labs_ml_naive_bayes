{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification with Naive Bayes\n",
    "\n",
    "The goal of this lab is to build a model using Naive Bayes to classify movie reviews into positive or negative, \n",
    "and then test the classifier on new movie reviews.\n",
    "\n",
    "The dataset is from the following publication: ''Thumbs up? Sentiment Classification using Machine Learning\n",
    "Techniques''. Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.\n",
    "Proceedings of EMNLP, pp. 79--86, 2002.\n",
    "Similar datasets can be found on [this site](https://www.cs.cornell.edu/people/pabo/movie-review-data/).\n",
    "\n",
    "Each review is stored in a separate text file. All the files are grouped into 2 subfolders: *pos* and *neg*.\n",
    "The dataset can be downloaded from here: [movies_reviews](https://drive.google.com/file/d/1rAJqDC8p6b5RWwoUT-0HwsxWk-b3j8cR/view?usp=sharing).\n",
    "\n",
    "- First of all, create a new Jupyther notebook, and implement a module that reads files and stores their content in 2 string arrays of file names.\n",
    "- Next, you would need to convert the words in each document into a vector of word occurrences. \n",
    "You can use the code with stop words from the clustering demo or you can use the `sklearn` module `feature_extraction.text`, \n",
    "where you are interested in the `CountVectorizer` (for this one you would need to remove stop words) or in the `TfidfTransformer`. \n",
    "The latter assigns a score to each word based on its frequencies across all the documents, \n",
    "and thus the words that occur across all the documents (the stop words) get score zero, so there is no need to remove stop words. You can find a nice explanation and an example about tf/idf score [here](https://medium.com/analytics-vidhya/tf-idf-term-frequency-technique-easiest-explanation-for-text-classification-in-nlp-with-code-8ca3912e58c3). Whatever vectorization technique you chose, you would need to explain it in your own words in a separate markdown cell in your notebook. \n",
    "- Once you have a vector for each review, you can add the labels *pos* or *neg*, depending on the directory (as we did in cat/dog classification demo), and then divide the dataset into training and testing.\n",
    "- Now use the train dataset to build a Naive Bayes model. You can use the `sklearn` module `naive_bayes` from [here](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.naive_bayes) to accomplish this task. Carefully select the correct classifier for the data at hand by reading about different classification options.\n",
    "- Test the accuracy on the train and on the test data. Try to reach the accuracy of at least 0.80.\n",
    "\n",
    "Finally, find 5 new movie reviews on the internet which include a numeric or star rating (known to be positive or negative), and try to classify them into positive/negative using your classifier. Report and discuss the results in a separate markdown cell.\n",
    "\n",
    "For starters, you can look at a demo of text classification [here](https://heartbeat.fritz.ai/understanding-naive-bayes-its-applications-in-text-classification-part-1-ec9caea4baae)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob('movies_reviews/*/*')\n",
    "res = []\n",
    "for file in files:\n",
    "    cl = file.split('\\\\')[-2]\n",
    "    with open(file, 'r') as f:\n",
    "        res.append([cl, f.read()])\n",
    "df = pd.DataFrame(res, columns=['sentiment', 'review'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>plot : two teen couples go to a church party ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>the happy bastard's quick movie review \\ndamn ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neg</td>\n",
       "      <td>it is movies like these that make a jaded movi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neg</td>\n",
       "      <td>\" quest for camelot \" is warner bros . ' firs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>synopsis : a mentally unstable man undergoing ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                             review\n",
       "0       neg  plot : two teen couples go to a church party ,...\n",
       "1       neg  the happy bastard's quick movie review \\ndamn ...\n",
       "2       neg  it is movies like these that make a jaded movi...\n",
       "3       neg   \" quest for camelot \" is warner bros . ' firs...\n",
       "4       neg  synopsis : a mentally unstable man undergoing ..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pos    1005\n",
       "neg    1000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1604, 39373) (401, 39373)\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(stop_words='english')\n",
    "X = vec.fit_transform(df['review'])\n",
    "y = df['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123, shuffle=True)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.72      0.85      0.78       196\n",
      "         pos       0.82      0.68      0.75       205\n",
      "\n",
      "    accuracy                           0.76       401\n",
      "   macro avg       0.77      0.76      0.76       401\n",
      "weighted avg       0.77      0.76      0.76       401\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb = BernoulliNB()\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred = nb.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1604, 4361) (401, 4361)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.77      0.83      0.80       196\n",
      "         pos       0.83      0.77      0.79       205\n",
      "\n",
      "    accuracy                           0.80       401\n",
      "   macro avg       0.80      0.80      0.80       401\n",
      "weighted avg       0.80      0.80      0.80       401\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(stop_words='english', max_df=.99, min_df=0.01)\n",
    "X = vec.fit_transform(df['review'])\n",
    "y = df['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123, shuffle=True)\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "nb = BernoulliNB()\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred = nb.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1604, 4361) (401, 4361)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.77      0.83      0.80       196\n",
      "         pos       0.83      0.77      0.79       205\n",
      "\n",
      "    accuracy                           0.80       401\n",
      "   macro avg       0.80      0.80      0.80       401\n",
      "weighted avg       0.80      0.80      0.80       401\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(stop_words='english', max_df=.99, min_df=0.01)\n",
    "X = vec.fit_transform(df['review'])\n",
    "y = df['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123, shuffle=True)\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "nb = BernoulliNB(alpha=1)\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred = nb.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1604, 4894) (401, 4894)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.77      0.83      0.80       196\n",
      "         pos       0.83      0.76      0.79       205\n",
      "\n",
      "    accuracy                           0.80       401\n",
      "   macro avg       0.80      0.80      0.80       401\n",
      "weighted avg       0.80      0.80      0.80       401\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(stop_words='english', max_df=.99, min_df=0.01, ngram_range=(1,3))\n",
    "X = vec.fit_transform(df['review'])\n",
    "y = df['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123, shuffle=True)\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "nb = BernoulliNB(alpha=1)\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred = nb.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1604, 39373) (401, 39373)\n"
     ]
    }
   ],
   "source": [
    "vec = TfidfVectorizer(stop_words='english')\n",
    "X = vec.fit_transform(df['review']).todense()\n",
    "y = df['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123, shuffle=True)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.64      0.59      0.62       196\n",
      "         pos       0.64      0.68      0.66       205\n",
      "\n",
      "    accuracy                           0.64       401\n",
      "   macro avg       0.64      0.64      0.64       401\n",
      "weighted avg       0.64      0.64      0.64       401\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred = nb.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.72      0.85      0.78       196\n",
      "         pos       0.82      0.68      0.75       205\n",
      "\n",
      "    accuracy                           0.76       401\n",
      "   macro avg       0.77      0.76      0.76       401\n",
      "weighted avg       0.77      0.76      0.76       401\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb = BernoulliNB()\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred = nb.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who would have thought that a movie about a ma...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>After realizing what is going on around us ......</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I grew up watching the original Disney Cindere...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>David Mamet wrote the screenplay and made his ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Admittedly, I didn't have high expectations of...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Reviews Sentiment\n",
       "0  Who would have thought that a movie about a ma...       pos\n",
       "1  After realizing what is going on around us ......       pos\n",
       "2  I grew up watching the original Disney Cindere...       neg\n",
       "3  David Mamet wrote the screenplay and made his ...       pos\n",
       "4  Admittedly, I didn't have high expectations of...       neg"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_extra = pd.read_csv('github_reviews\\gbReviewsSample.csv')\n",
    "df_extra.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1604, 4361) (401, 4361)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.77      0.83      0.80       196\n",
      "         pos       0.83      0.77      0.79       205\n",
      "\n",
      "    accuracy                           0.80       401\n",
      "   macro avg       0.80      0.80      0.80       401\n",
      "weighted avg       0.80      0.80      0.80       401\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(stop_words='english', max_df=.99, min_df=0.01)\n",
    "X = vec.fit_transform(df['review'])\n",
    "y = df['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123, shuffle=True)\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "nb = BernoulliNB()\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred = nb.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_extra = vec.transform(df_extra['Reviews'])\n",
    "y_pred = nb.predict(X_extra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neg', 'neg', 'neg', 'pos', 'neg'], dtype='<U3')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['pos', 'pos', 'neg', 'pos', 'neg'], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_extra['Sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Who would have thought that a movie about a man who drives a couple hundreds of miles on his lawn mower to see his brother, could possibly be good cinema? I certainly didn\\'t. I thought I knew what to expect: one of the most boring experiences of my life. Well I was as wrong as I haven\\'t been wrong too often yet, because this is one of the best, most realistic and honest Hollywood films I\\'ve ever seen...<br /><br />Giving a short resume of \"The Straight Story\" isn\\'t very difficult. It\\'s about an old and stubborn man who steps on his lawn mower and drives off to another state to pay his brother a visit when he hears that the man has had a severe stroke. That\\'s already special on itself, but what makes it even more special is the fact that he hasn\\'t seen his brother in ten years because of some stupid argument. In the meantime he has his share of bad luck and problems, but he also meets a lot of people whose lives he influences in one way or another with his philosophical approach to life. Despite all the difficulties he drives on for weeks, not knowing if he will reach his goal: seeing his brother again before it\\'s too late...<br /><br />I can easily understand why there are people who don\\'t like this movie and that\\'s also the reason why I will not say that these people don\\'t have a heart or things like that... This movie hasn\\'t got any flashy action scenes, it is as slow as the lawn mower the man is driving on and no, you don\\'t have to watch it for the nice soundtrack either, because there isn\\'t any. But why should you watch it then? Well, the simple answer is the story. I haven\\'t seen such a touching movie with such a powerful story very often and the fact that this actually comes from Hollywood and - to make things even better - from the Disney Studio\\'s (that\\'s right, the same studios that overwhelm us with sugar sweet nonsense) makes it even more special. I\\'m not ashamed to admit that I had the tears in my eyes a couple of times while watching it, probably because the whole situation of not seeing someone for many years because of some stupid argument is all too realistic for me.<br /><br />Some people will argue that the story is very shallow, but I really don\\'t agree with that. Perhaps it is because they only see that old man driving on his lawn mower and don\\'t want to think any further. If you look close enough than you\\'ll understand that this man is doing all this because he knows he has once been wrong, that only his pride stood in the way of seeing his brother again and that he wants everybody else to see that too, so they won\\'t make the same mistake. If that isn\\'t deep enough, how much deeper does a story have to go for you then? <br /><br />I would also like to add that this movie really had it all. Some beautiful landscapes (finally an American movie that shows something else than the skyline of New York, Chicago or some other big city), some very fine acting by Richard Farnsworth, Sissy Spacek,... and a very understandable way of telling despite the fact that this is a David Lynch movie. I know now that I was completely wrong by assuming that this movie wouldn\\'t be to my taste. It\\'s one of the very best movies I\\'ve seen in a long time. This movie aimed for my heart and hit the bull\\'s eye. I give it the full 10/10.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_extra['Reviews'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a new set of data, the best model misclassified two of its predictions. It may be that the new data from the sample of five reviews contains both negative and positive words that misrepresent the overall review. Since the model has an 80% margin of accuracy, it is acceptable that it wrongly predicted two revisions out of five."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "665796ea3363072d3a6057ac2fdbe3c4fcb0d17a4b92295d9707f78e9c46c0af"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
